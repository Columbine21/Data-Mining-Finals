# æ•°æ®ä»“åº“ä¸æ•°æ®æŒ–æ˜ æœŸæœ«ä½œä¸šæŠ¥å‘Š



## ï¼ˆä¸€ï¼‰ åˆ†ææ•°æ®é›†æ¦‚è¿°  

### 		æ•°æ®æ¥æº

æœ¬æ¬¡å®éªŒä¸­ä½¿ç”¨çš„æ•°æ®é›†æ¥è‡ªkaggleç½‘ç«™ä¸ŠFIFA19çƒå‘˜æ•°æ®é›†ï¼ŒåŸå§‹æ•°æ®é›†ç½‘å€å¦‚ä¸‹ï¼š

â€‹														 [https://www.kaggle.com/karangadiya/fifa19](https://www.kaggle.com/karangadiya/fifa19)

Noteï¼šåŒæ—¶ï¼Œæ³¨æ„åˆ°åŸå§‹æ•°æ®é›†ä¸­å­˜åœ¨å¤§é‡æ— å…³ä¿¡æ¯ï¼Œæˆ‘ä»¬åœ¨è¿›è¡Œæ•°æ®æ¸…æ´—æ­¥éª¤ä¸­åˆ é™¤äº†éƒ¨åˆ†æ— ç”¨çš„å±æ€§ï¼ˆè¿™ä¸€éƒ¨åˆ†ä¼šåœ¨åé¢çš„åˆ†ææµè®¾è®¡ä¸­è¿›è¡Œä½“ç°ï¼‰

ï¼ˆæˆ‘ä»¬ä¿å­˜äº†æ¸…æ´—ä¹‹åçš„æ•°æ®é›†ï¼Œæˆ‘ä»¬å°†æ¸…æ´—ä¹‹åçš„æ•°æ®é›†ä¿å­˜åˆ°åŒè·¯å¾„æ–‡ä»¶å¤¹ä¸‹ã€‚ï¼‰

### 		å±æ€§åç§°ä¸å±æ€§ç±»å‹

è¿›è¿‡ç­›é€‰åï¼Œæˆ‘ä»¬ä½¿ç”¨pd.describe().T.to_csv("description.csv")å‘½ä»¤,å°†æˆ‘ä»¬çš„ç»Ÿè®¡é‡è¾“å‡ºåˆ°csvæ–‡ä»¶ä¸­ã€‚

è¯¥æ–‡ä»¶ï¼ˆdescription.csvåœ¨datağŸ“ä¸‹ï¼‰ä¸ºäº†ç›´è§‚ï¼Œæ˜¾ç¤ºå¦‚ä¸‹ï¼š

<img src="å±å¹•å¿«ç…§ 2019-12-15 ä¸‹åˆ4.12.34.png" alt="description"  />

###  	   æ•°æ®è§„æ¨¡

åŸå§‹æ•°æ®é›†å¤§å°ï¼š(18207, 89) ã€‚æˆ‘ä»¬ç»è¿‡é¢„å¤„ç†åçš„æ•°æ®é›†å¤§å°ï¼š(18147, 34) 

### 		æ•°æ®æ ·ä¾‹

æˆ‘ä»¬ä½¿ç”¨pandasä¸­DataFrameç±»å‹å†…ç½®çš„å‡½æ•°.head()æ¥æŸ¥çœ‹æ•°æ®æ ·ä¾‹ã€‚

(ç„¶è€Œå¹¶æ˜¾ç¤ºä¸ä¸‹ï¼Œäºæ˜¯é‡‡ç”¨csvæ–‡ä»¶æˆªå›¾æ–¹å¼åœ¨è¿™é‡Œè¿›è¡Œå±•ç¤ºå‰ 10æ¡è®°å½•)

![](å±å¹•å¿«ç…§ 2019-12-15 ä¸‹åˆ4.01.25.png)



## ï¼ˆäºŒï¼‰åˆ†æç›®æ ‡  

æè¿°æ•°æ®åˆ†æé¢„æœŸæŒ–æ˜ç›®æ ‡ï¼ŒæŒ–æ˜ä»€ä¹ˆæ ·çš„æ¨¡å‹ã€‚

1.  æ ¹æ®çƒå‘˜å„é¡¹èƒ½åŠ›å€¼å¯¹çƒå‘˜çš„åœºä¸Šä½œç”¨è¿›è¡Œåˆ†ç±»ã€‚
    -   æˆ‘ä»¬çŸ¥é“åœ¨è¶³çƒé˜Ÿä¸­ï¼Œå¯ä»¥å°†æ¯ä¸€ä¸ªçƒå‘˜ç²—ç•¥çš„åˆ†æˆä»¥ä¸‹å‡ ç±»ï¼š
        -   é—¨å°† ("goalkeeper") : 0  	ååœº ("defender") : 1 ä¸­åœº("midfielder") : 2 	å‰é”‹("forward") : 3
    -   æœ¬æ­¤å®éªŒä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ç¥ç»ç½‘ç»œï¼ˆpythonï¼‰å¯¹æ¯”SPSSä¸­åˆ†ç±»æ¨¡å‹ï¼Œåˆ©ç”¨æ•°æ®é›†ä¸­æä¾›çš„ä¸ªçƒå‘˜èƒ½åŠ›å€¼å¯¹çƒå‘˜åœºä¸Šä½œç”¨ï¼ˆä½ç½®ï¼‰è¿›è¡Œé¢„æµ‹ã€‚
2.  çƒå‘˜èƒ½åŠ›å€¼èšç±»ä»»åŠ¡ã€‚
    -   åˆ©ç”¨æˆ‘ä»¬åŸå§‹æ•°æ®é›†ä¸­å„ä¸ªçƒå‘˜çš„èƒ½åŠ›å€¼ï¼Œæˆ‘ä»¬å°è¯•æ‰ç”¨æ— ç›‘ç£çš„æ–¹å¼å°†çƒå‘˜è¿›è¡Œèšç±»ã€‚
    -   åˆ©ç”¨ï¼ˆsklearn åº“ä¸­ KMeansæ¨¡å‹ï¼‰å¯¹æ¯”SPSSä¸­çš„èšç±»èŠ‚ç‚¹ï¼Œå¯¹çƒå‘˜èƒ½åŠ›è¿›è¡Œèšç±»ã€‚
    -   åˆ©ç”¨PCAå°†çƒå‘˜èƒ½åŠ›å€¼è¿›è¡Œé™ç»´ï¼Œé€šè¿‡ï¼ˆmatplotlibï¼‰ä½œå›¾å¯¹äºèšç±»ç»“æœè¿›è¡Œå¯è§†åŒ–ã€‚
3.  çƒå‘˜å¹´é¾„å’Œçƒå‘˜æ½œåŠ›å€¼çš„å…³è”è§„åˆ™
    -   ä»ç›´è§‰ä¸Šæ¥è¯´ï¼Œå¯¹äºä¸€ä¸ªå¹´è½»çƒå‘˜ï¼Œå…¶å¾€å¾€æœ‰æ›´å¤§çš„ä¸Šå‡ç©ºé—´ï¼Œæœ¬å®éªŒä¸­ç ”ç©¶è¿™ç§â€œAssociationâ€æ˜¯å¦çœŸæ­£æˆç«‹
    -   åˆ©ç”¨SPSSå¯¹äºå…³è”è§„åˆ™è¿›è¡Œåˆ†æ

## ï¼ˆä¸‰ï¼‰åˆ†ææµè®¾è®¡  & Python æ•°æ®åˆ†æè®¾è®¡è¿‡ç¨‹

 æ³¨ï¼šè¯´æ˜modeleré¢„å¤„ç†ã€å»ºæ¨¡æ­¥éª¤ï¼Œæ¯ä¸ªæ­¥éª¤è®¡ç®—ç”¨ä»€ä¹ˆèŠ‚ç‚¹åšä»€ä¹ˆå·¥ä½œã€‚

### 	task 1 çƒå‘˜ä½ç½®åˆ†ç±»ä»»åŠ¡

#### 			Python æ•°æ®åˆ†æè®¾è®¡è¿‡ç¨‹

-   æ•°æ®é›†é¢„å¤„ç†ï¼š

    -   é¦–å…ˆå…ˆåˆ é™¤çƒå‘˜ä½ç½®å±æ€§ä¸ºç©ºçš„è®°å½•ã€‚ï¼ˆ**<u>å¤„ç†ç©ºå€¼çš„æ–¹æ³•</u>**ï¼‰

    -   ç„¶åï¼Œæˆ‘ä»¬æ ¹æ®åŸå§‹æ•°æ®ä¸­postionå±æ€§å†…å®¹ä¸ºæ¯æ¡çƒå‘˜è®°å½•å¢åŠ ä¸€ä¸ªdutyå±æ€§ï¼Œæ•°å€¼ç±»å‹å±æ€§ã€‚

        dutyå±æ€§åˆ†æˆå››ç±»ï¼šé—¨å°† ("goalkeeper") : 0  	ååœº ("defender") : 1 

        â€‹									ä¸­åœº("midfielder") : 2 	å‰é”‹("forward") : 3

        postionï¼Œ dutyå¯¹åº”å…³ç³»å¦‚ä¸‹æ‰€ç¤ºï¼š

        | Postion                                                      | Duty |
        | ------------------------------------------------------------ | ---- |
        | "ST", "LW", "RW", "LF", "RF", "RS","LS", "CF"                | 3    |
        | "CM","RCM","LCM", "CDM","RDM","LDM", "CAM", "LAM", "RAM", "RM", "LM" | 2    |
        | "CB", "RCB", "LCB", "LWB", "RWB", "LB", "RB"                 | 1    |
        | â€œGKâ€                                                         | 0    |

    -   ä¹‹åï¼Œæˆ‘ä»¬ä»åŸå§‹æ•°æ®ä¸­æ™’é€‰å‡ºçƒå‘˜èƒ½åŠ›å€¼çš„æ•°æ®ä½œä¸ºæˆ‘ä»¬æ¨¡å‹çš„è¾“å…¥ã€‚çƒå‘˜èƒ½åŠ›å€¼è¯¦ç»†è§£é‡Šè¡¨ï¼ˆè§é™„å½•ï¼ˆä¸€ï¼‰ï¼‰ï¼š

    -   ç„¶ååˆ©ç”¨sklearnä¸­ sklearn.preprocessing StandardScaler å¯¹æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–ã€‚
    -   åˆ©ç”¨keras.utils.np_utils to_categoricalå‡½æ•°å°†æ•°å€¼ç±»å‹çš„targetè½¬æ¢ä¸ºone-hotç¼–ç ï¼Œæ–¹ä¾¿ä¹‹åä½¿ç”¨å†…ç½®çš„categorical_crossentropyæŸå¤±å‡½æ•°ã€‚
    -   æœ€ååˆ©ç”¨sklearn.model_selection train_test_splitå‡½æ•°åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚

-   ä½¿ç”¨ä¼ ç»Ÿæ·±åº¦å­¦ä¹ æ¨¡å‹ ï¼šlinearå±‚å»ºæ¨¡ï¼Œæœ€åçš„è¾“å‡ºä½¿ç”¨softmaxä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œå…¶ä½™å±‚ä½¿ç”¨reluæ¿€æ´»ï¼Œåœ¨æœ€åä¸€å±‚ä¹‹å‰å¢åŠ dropouté˜²æ­¢è¿‡æ‹Ÿåˆã€‚å¾—åˆ°æˆ‘ä»¬å®éªŒä¸­ä½¿ç”¨çš„æ¨¡å‹ã€‚

-   æ¨¡å‹è®­ç»ƒ & æµ‹è¯•

    -   æµ‹è¯•ç»“æœä½¿ç”¨confuse_matrixè¿›è¡Œç»Ÿè®¡ï¼Œå¹¶è¿›è¡Œç®€å•çš„å¯è§†åŒ–å·¥ä½œã€‚

        #### SPSSæµè®¾è®¡

-   ç”±äºæˆ‘ä»¬å·²ç»ç”¨pythonè¿›è¡Œäº†æ•°æ®é¢„å¤„ç†å·¥ä½œï¼Œ æˆ‘ä»¬ç›´æ¥ä½¿ç”¨ä½¿ç”¨pythonæ•°æ®é¢„å¤„ç†åçš„æ•°æ®è¿›è¡Œåˆ†æã€‚
-   æˆ‘ä»¬é¦–å…ˆä½¿ç”¨å˜é‡æ–‡ä»¶èŠ‚ç‚¹å°†é¢„å¤„ç†å¥½çš„æ–‡ä»¶è¿›è¡Œå¯¼å…¥

![](å±å¹•å¿«ç…§ 2019-12-15 ä¸‹åˆ6.16.32.png)


-   ä½¿ç”¨è¿‡æ»¤å™¨å°†idç¼–å·å»æ‰

![](å±å¹•å¿«ç…§ 2019-12-15 ä¸‹åˆ6.21.49.png)

-   ä½¿ç”¨æ ·æœ¬èŠ‚ç‚¹åˆ’åˆ†æ•°æ®é›†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†

![](å±å¹•å¿«ç…§ 2019-12-15 ä¸‹åˆ6.22.29.png)

-   ä½¿ç”¨ç±»å‹èŠ‚ç‚¹å°†éœ€è¦é¢„æµ‹çš„Dutyå±æ€§è®¾ç½®ä¸ºç›®æ ‡ï¼Œç±»å‹è®¾ç½®ä¸ºæ ‡è®°ç±»å‹ã€‚

![](å±å¹•å¿«ç…§ 2019-12-15 ä¸‹åˆ6.23.08.png)

-   ä½¿ç”¨C5.0 å†³ç­–æ ‘æ¨¡å‹å®Œæˆå¤šåˆ†ç±»ä»»åŠ¡ã€‚

-   ä½¿ç”¨åˆ†æèŠ‚ç‚¹å¯¹æ¨¡å‹èƒ½åŠ›è¿›è¡Œåˆ†æ

![](å±å¹•å¿«ç…§ 2019-12-15 ä¸‹åˆ6.23.49.png)

### 	task 2 çƒå‘˜èƒ½åŠ›å€¼èšç±»ä»»åŠ¡

#### 		Python æ•°æ®åˆ†æè®¾è®¡è¿‡ç¨‹

-   æ•°æ®é›†é¢„å¤„ç†ï¼š
    -   è¿™é‡Œçš„æ•°æ®é¢„å¤„ç†è¿‡ç¨‹å’Œä¸Šé¢çš„task 1ä¸­çš„æ•°æ®é¢„å¤„ç†æ¯”è¾ƒç±»ä¼¼ï¼Œç”±äºä¸éœ€è¦è€ƒè™‘çƒå‘˜ä½ç½®åŒæ—¶è€ƒè™‘åˆ°ä»»åŠ¡æœ¬èº«ä¸ºæ— ç›‘ç£ä»»åŠ¡ï¼Œæˆ‘ä»¬è¿™é‡Œåªéœ€è¦åœ¨ç­›é€‰èƒ½åŠ›å€¼æ•°æ®åï¼Œå¯¹æ•°æ®è¿›è¡Œæ•°æ®æ ‡å‡†åŒ–å³å¯ã€‚
-   ä½¿ç”¨K-meansæ¨¡å‹ï¼šå°†èƒ½åŠ›å€¼åˆ†æˆå››ç±»ï¼ˆä»ç„¶æƒ³ä½“ç°çƒå‘˜åœ¨ä¸åŒä½ç½®ä¸Šä½œç”¨åº”å½“æœ‰æ˜¾è‘—å·®å¼‚ï¼‰ã€‚
-   æ¨¡å‹è®­ç»ƒ ï¼š
    -   å…·ä½“æ¨¡å‹å‚æ•°ï¼š 
    -   æ¨¡å‹æŸå¤±å€¼ï¼š
-   æ¨¡å‹æ•ˆæœå±•ç¤ºï¼šå¹¶åˆ©ç”¨PCAå°†çƒå‘˜èƒ½åŠ›å€¼é™åˆ°äºŒç»´ï¼Œå¯¹æˆ‘ä»¬çš„K-meansæ¨¡å‹ç»“æœè¿›è¡Œå¯è§†åŒ–



#### 	  SPSSæµè®¾è®¡

-   åŒå®éªŒä¸€ï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨å˜é‡æ–‡ä»¶èŠ‚ç‚¹å°†é¢„å¤„ç†å¥½çš„æ–‡ä»¶è¿›è¡Œå¯¼å…¥

![](å±å¹•å¿«ç…§ 2019-12-15 ä¸‹åˆ7.19.09.png)

-   ä½¿ç”¨ç±»å‹èŠ‚ç‚¹å°†IDï¼ŒDutyè¡¨é¡¹è§’è‰²è®¾ç½®ä¸ºæ— ï¼Œå…¶ä½™è¡¨é¡¹è§’è‰²ä¸ºè¾“å…¥ï¼Œå¹¶å°†Dutyè¡¨é¡¹å®šä¹‰ä¸ºåä¹‰å±æ€§ã€‚

![](å±å¹•å¿«ç…§ 2019-12-15 ä¸‹åˆ7.21.40.png)

-   ä½¿ç”¨K-MeansèŠ‚ç‚¹å°†èšç±»æ•°ç›®è®¾å®šä¸º4è¿›è¡Œè®­ç»ƒ

![](å±å¹•å¿«ç…§ 2019-12-15 ä¸‹åˆ7.25.11.png)

-   å°†ç»“æœæŒ‰ç…§Dutyå±æ€§ï¼Œå’Œé¢„æµ‹èšç±»ç±»å‹æ’åº

![](å±å¹•å¿«ç…§ 2019-12-15 ä¸‹åˆ7.25.29.png)

-   ä½¿ç”¨çŸ©é˜µèŠ‚ç‚¹è§‚å¯Ÿconfuse matrix

    ![](å±å¹•å¿«ç…§ 2019-12-15 ä¸‹åˆ7.25.36-6409199.png)

    

    ### task 3 çƒå‘˜å¹´é¾„ä¸çƒå‘˜æ½œåŠ›å€¼å…³è”è§„åˆ™åˆ†æ

ï¼ˆç•¥ï¼‰

## ï¼ˆå››ï¼‰åˆ†ææµå®ç°  

â€‹         æ³¨ï¼šè¯´æ˜modeleråˆ†ææµçš„å…·ä½“å†…å®¹ï¼šæ•°æ®é¢„å¤„ç†ã€æ•°æ®æŒ–æ˜å»ºæ¨¡ã€æ¨¡å‹ç»“æœã€æ¨¡å‹è¯„ä¼°æ•ˆæœåˆ†æï¼›è¦æ±‚æµæ ¹æ®æˆªå›¾è¿›è¡Œè¯´æ˜ï¼Œæµå¯åˆ†ä¸ºå¤šä¸ªæ–‡ä»¶ï¼›ä¹Ÿå¯åˆ†ä¸ºå¤šä¸ªæµè¿›è¡Œåˆ†æ  

### 	Task one åˆ†ç±»ä»»åŠ¡

#### 		Python ç¥ç»ç½‘ç»œç‰ˆ

##### æ•°æ®é¢„å¤„ç†

-   Step one : filter out the record without 'Postion' attributes

```python
player_data = pd.read_csv("../input/fifa19/data.csv", header=0,  na_values=['.', '??','?', '', ' ', 'NA', 'na', 'Na', 'N/A', 'N/a', 'n/a'])

legal_index = pd.notnull(player_data['Position'])

player_data = player_data.loc[legal_index]

player_data.index = range(len(player_data))
```

-   Step two : add Duty attribute

```python
forward = ["ST", "LW", "RW", "LF", "RF", "RS","LS", "CF"]
midfielder = ["CM","RCM","LCM", "CDM","RDM","LDM", "CAM", "LAM", "RAM", "RM", "LM"]
defender = ["CB", "RCB", "LCB", "LWB", "RWB", "LB", "RB"]

player_data.loc[player_data["Position"] == "GK", "Duty"] = 0
player_data.loc[player_data["Position"].isin(defender), "Duty"] = 1
player_data.loc[player_data["Position"].isin(midfielder), "Duty"] = 2
player_data.loc[player_data["Position"].isin(forward), "Duty"] = 3

player_data['Duty'] = player_data['Duty'].astype('int')
```

-   Step three : filter out columns without ability info.

```python
ability = ['Finishing', 'HeadingAccuracy', 'ShortPassing', 'Volleys', 'Dribbling',
       'Curve', 'FKAccuracy', 'LongPassing', 'BallControl', 'Acceleration',
       'SprintSpeed', 'Agility', 'Reactions', 'Balance', 'ShotPower',
       'Jumping', 'Stamina', 'Strength', 'LongShots', 'Aggression',
       'Interceptions', 'Positioning', 'Vision', 'Penalties', 'Composure',
       'Marking', 'StandingTackle', 'SlidingTackle', 'GKDiving', 'GKHandling',
       'GKKicking', 'GKPositioning', 'GKReflexes', 'Duty']

player_data_filtered = player_data[ability]
```

-   Step four : fill the ability attribute of null with the mean_value of the column. 

```python
# but in fact our dataset is complete enough with no null values now ! so there is no need to fill the null values.
col_with_null = [col for col in player_data_filtered.columns
                if player_data_filtered[col].isnull().any()]

print(col_with_null)
```

-   Step five : save our filtered data

```python
player_data_filtered.to_csv('/kaggle/working/filtered_data.csv')
```

-   Step Six : get the description

```python
print(player_data_filtered.shape)

player_data_filtered.describe().T.to_csv('/kaggle/working/description.csv')
```

-   Step Seven : standardlize the attributes of players.

```python
X = player_data_filtered.drop("Duty", axis = 1)

from sklearn.preprocessing import StandardScaler

Scaler = StandardScaler()

X = Scaler.fit_transform(X)

Y = player_data_filtered['Duty']
```

-   Step Eight : split our traininng and test set.

```python
x_train = X[:14000]; y_train = Y[:14000]

x_test = X[14000:]; y_test = Y[14000:]
y_test.index = range(len(x_test))

# Step two : construct our dataset.
import torch.utils.data as data
import torch
class Player_Dataset(data.Dataset):
    def __init__(self, x, y):
        self.input = x
        self.target = y
    def __getitem__(self, index):
        return self.input[index], self.target[inex]
    def  __len__(self):
        return len(self.target)
    
train_dataset = Player_Dataset(x_train, y_train)

test_dataset = Player_Dataset(x_test, y_test)

# Step Three : construct our dataloader.
train_iter = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32, shuffle=True, num_workers=4)

test_iter = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=32, shuffle=True, num_workers=4)
```

##### æ­å»ºç¥ç»ç½‘ç»œæ¨¡å‹

-   Step one : build our model 

```python
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class Classifier(nn.Module):
    def __init__(self, input_size, output_size, dropout):
        super(Classifier, self).__init__()
        self.dropout = dropout
        self.output_size = output_size
        self.input_size = input_size
        
        self.linear_1 = nn.Linear(input_size, 128)
        self.linear_2 = nn.Linear(128, 128)
        self.dropout = nn.Dropout(dropout)
        self.linear_3 = nn.Linear(128, output_size)
        
    def forward(self, input):
        temp_result = F.relu(self.linear_1(input))
        temp_result = F.relu(self.linear_2(temp_result))
        temp_result = self.dropout(temp_result)
        result = F.softmax(self.linear_3(temp_result), dim=1)
        return result
    
model = Classifier(33, 4, 0.5).to(device)

```

-   Step two : define our optimizer and criterion

```python
optimizer = optim.Adam(model.parameters())

criterion = nn.CrossEntropyLoss().to(device)
```

-   Step Three : train our model

```python
def train(model, data, optimizer, criterion):
    model.train()
    epoch_loss = 0
    for i, batch in enumerate(data):
        Input, target = batch
        Input = Input.float().to(device); target = target.to(device)
        output = model(Input)
        loss = criterion(output, target)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        epoch_loss += loss.item()
        
    return epoch_loss / len(data)
```

```python
N_epoches = 10
best_valid_loss = float('inf')

for epoch in range(N_epoches):
    
    start_time = time.time()
    
    train_loss = train(model, train_iter, optimizer, criterion)
    
    end_time = time.time()
    
    epoch_mins, epoch_secs = epoch_time(start_time, end_time)
    
    if train_loss < best_valid_loss:
        best_valid_loss = train_loss
        torch.save(model.state_dict(), 'model.pt')
        
    print(f'Epoch:  {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')
    print(f'\tTrain  Loss: {train_loss: .3f}')
```

#### 		SPSS æµå®ç°

![](å±å¹•å¿«ç…§ 2019-12-15 ä¸‹åˆ6.14.29.png)


### 	Task two èšç±»ä»»åŠ¡

#### 		Python ç¥ç»ç½‘ç»œç‰ˆ

-   Build our experiment model using sklearn.

```python
from sklearn.cluster import KMeans
from sklearn import metrics

# using sklearn create KMeans model to do our experiments.
KMean_model = KMeans(n_clusters=4, random_state=9)
y_pred = KMean_model.fit_predict(X)
```

-   å¯ä»¥çœ‹å‡ºä½¿ç”¨sklearn çš„æœºå™¨å­¦ä¹ æ–¹æ³•å°±æ˜¯è¿™æ ·ç®€å•ç›´æ¥ï¼ŒçŸ­çŸ­4è¡Œä»£ç å°†KMeansèšç±»æ–¹æ³•å±•ç°ç»™äº†ä½¿ç”¨è€…ã€‚

    #### 	SPSSæµå®ç°

![](å±å¹•å¿«ç…§ 2019-12-15 ä¸‹åˆ7.06.06.png)

-   è¿™é‡Œè¡¥å……ä¸€ä¸‹ï¼šåœ¨æœ¬æ¬¡å®éªŒä¸­ï¼Œæˆ‘ä½¿ç”¨äº†ä¸¤ç§å®Œå…¨ä¸åŒçš„æœºå™¨å­¦ä¹ /æ·±åº¦å­¦ä¹ åº“ï¼Œpytorch & sklearnã€‚
    -   ç®€å•æ¥è¯´ï¼Œsklearnå°è£…äº†å‡ ä¹æ‰€æœ‰ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œæˆ‘ä»¬éœ€è¦åšçš„å°±æ˜¯å®šä¹‰æ¨¡å‹ï¼Œæ„é€ æ•°æ®é›†ï¼Œfit+predict å®Œæˆæˆ‘ä»¬å¯¹äºæœªçŸ¥å€¼çš„é¢„æµ‹ã€‚
        -   è¿™ç§ç®€å•ç²—æš´çš„æ–¹æ³•é€‚åˆå¤§éƒ¨åˆ†å…¸å‹åœºæ™¯åº”ç”¨ï¼Œæ¯”è¾ƒé€‚åˆåšå•†ä¸šå¼€å‘ä½¿ç”¨ï¼Œæ•ˆæœä¸é”™ã€‚
        -   ç„¶è€Œè¿™ç§æ–¹æ³•å¯¹äºæ›´åŠ å¤æ‚çš„æ¨¡å‹æ•ˆæœæœ‰ä¸€å®šå±€é™ï¼Œå¯ä»¥åšbaselineï¼Œä½†ä¸ä¼šæ˜¯STOAã€‚
        -   Noteï¼š sklearn è²Œä¼¼ä¸æ”¯æŒGPUåŠ é€Ÿï¼Œè¿™ä¹Ÿæ˜¯å¦ä¸€ä¸ªé—®é¢˜
    -   å¯¹äºpytorchï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å…´çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæœ¬äººåœ¨åˆæ¬¡æ¥è§¦çš„æ—¶å€™ç¡®å®æ„Ÿè§‰æ¯”è¾ƒæ™¦æ¶©éš¾æ‡‚ã€‚
        -   è¿™ç§æ–¹æ³•æ˜æ˜¾ä»£ç é‡è¿œå¤§äºsklearn/kerasã€‚
        -   è¿™ç§æ–¹æ³•çš„å¯è°ƒå¼æ€§æ›´å¼ºå¤§ï¼Œè¾ƒäºkeras/sklearn èƒ½åŠ›æ›´å¼ºï¼Œä½¿ç”¨äºæ›´åŠ å¹¿æ³›çš„åœºæ™¯ã€‚

## ï¼ˆäº”ï¼‰æ•°æ®åˆ†ææ€»ç»“

### 	Task one åˆ†ç±»ä»»åŠ¡

#### 		Python ç»“æœåˆ†æ

è¿™ä¸ªé—®é¢˜æ˜¯ä¸€ä¸ªå…¸å‹çš„å››åˆ†ç±»ä»»åŠ¡ï¼šå°†çƒå‘˜æŒ‰åœºä¸Šä½ç½®åˆ†æˆå››ç±»ã€‚

éšæœºåˆ†ç±»çš„å‡†ç¡®åº¦åº”è¯¥ä¸è¶…è¿‡30%, æˆ‘ä»¬ä½¿ç”¨åˆ†ç±»æ­£ç¡®æ‰€å æ¯”å¯¹äºæ¨¡å‹çš„æ•ˆæœè¿›è¡Œæµ‹è¯•ï¼š

å¤šæ¬¡å®éªŒè¡¨æ˜ï¼š æˆ‘ä»¬çš„æ¨¡å‹ç²¾ç¡®åº¦åœ¨87.5%-88.5%ä¹‹é—´ ï¼ˆéªŒè¯æ¨¡å‹ç²¾ç¡®åº¦ä»£ç å¦‚ä¸‹ï¼šï¼‰

```python
from sklearn.metrics import classification_report

def evaluate():
    result_on_test = []; ground_truth = []
    model.eval()
    for i, batch in enumerate(test_iter):
        features, target = batch
        ground_truth.extend(list(target))
        with torch.no_grad():
            output = model(features.float())
            output = np.argmax(output, axis=1)
            result_on_test.extend(output)
            
    acc = sum([(ground_truth[i] == result_on_test[i]).item() for i in range(len(result_on_test))]) / len(result_on_test)
    print(f"The classification accuracy is : {acc*100:.2f} %\n")   
    print(classification_report(ground_truth, result_on_test))
```

æ¨¡å‹ä¸€æ¬¡æµ‹è¯•ç»“æœï¼š

<img src="å±å¹•å¿«ç…§ 2019-12-15 ä¸‹åˆ4.27.18.png" style=
"zoom:50%;" />

æ¨¡å‹æ•ˆæœåˆ†æï¼šæ€»ä½“æ¥è¯´æ¨¡å‹å¯¹äºå››ç§ç±»å‹å‡èƒ½è¾¾åˆ°è¾ƒå¥½çš„æ•ˆæœï¼Œæ¨¡å‹åŒºåˆ†å®ˆé—¨å‘˜ï¼ˆ0ï¼‰çš„èƒ½åŠ›å°¤å…¶ä¹‹å¼ºã€‚

#### 		SPSS ç»“æœåˆ†æ

![](å±å¹•å¿«ç…§ 2019-12-15 ä¸‹åˆ6.10.33.png)

#### 	Python & SPSSç»“æœå¯¹æ¯”

-   Python æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®åº¦è¾ƒSPSSå‡†ç¡®åº¦é«˜9%å·¦å³ã€‚

    ### Task two èšç±»ä»»åŠ¡

    #### 	Python ç»“æœåˆ†æ			

æˆ‘ä»¬ä½¿ç”¨KMeanså°†çƒå‘˜çš„å„ä¸ªèƒ½åŠ›å€¼ï¼ˆé™¤å»dutyåˆ—ï¼‰è¿›è¡Œèšç±»ï¼ˆå››ç±»ï¼‰ï¼š

ç›´è§‰ä¸Šï¼Œæˆ‘ä»¬ä»ç„¶è®¤ä¸ºèšç±»ä»»åŠ¡çš„æ•ˆæœä»åº”è¯¥å’Œä¹‹å‰å¯¹äºçƒå‘˜ä¸åŒä½œç”¨çš„åˆ†ç±»æœ‰ç›¸ä¼¼ä¹‹å¤„ï¼ˆä¸åŒä½ç½®çš„çƒå‘˜åº”å½“æœ‰ä¸åŒçš„èƒ½åŠ›ç‰¹å¾ï¼Œç›¸åŒä½ç½®çš„çƒå‘˜åº”è¯¥æœ‰ç›¸ä¼¼çš„èƒ½åŠ›ç‰¹å¾ï¼‰ã€‚

åŸºäºæ­¤ï¼Œæˆ‘ä»¬ä»ä½¿ç”¨Dutyä½œä¸ºä¸€é¡¹æ ‡å‡†è¿›è¡Œæ¯”è¾ƒã€‚

-   é¦–å…ˆä½¿ç”¨PCAå°†çƒå‘˜33ä¸­èƒ½åŠ›å€¼è¿›è¡Œå‹ç¼©ï¼Œå‹ç¼©åˆ°2ç»´ï¼Œå¹¶å¯¹å…¶ä½¿ç”¨matplotlibè¿›è¡Œå¯è§†åŒ–ã€‚

```python
from sklearn.decomposition import PCA
from sklearn import metrics
%pylab inline

pca = PCA(n_components=2)
X_decomposition = pca.fit_transform(X)
fig = plt.figure(figsize=(5, 5))
plt.scatter(X_decomposition[:, 0], X_decomposition[:,1], c = y_pred,
                 cmap = plt.cm.get_cmap("tab10", 10), alpha = 0.5)
```

<img src="å±å¹•å¿«ç…§ 2019-12-15 ä¸‹åˆ4.36.35.png"  />

é€šè¿‡å¯è§†åŒ–ï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°æˆ‘ä»¬çš„èšç±»æ•ˆæœä¸é”™ã€‚

åŒæ—¶çŒœæµ‹ç²‰è‰²åº”è¯¥ä¸å®ˆé—¨å‘˜ç±»å‹å¯¹åº”ï¼Œå…¶ä½™ä½ç½®åœ¨å‹ç¼©åæ²¡æœ‰å¾ˆæ˜æ˜¾çš„è¾¹ç•Œã€‚

-   å…¶æ¬¡æˆ‘ä»¬æ‰‹å†™äº†ä¸€ä¸ªä¼˜é›…çš„ç»˜åˆ¶confuse_matrixçš„å‡½æ•°ã€‚æ£€éªŒäº†èšç±»æ•ˆæœ

```python
from sklearn.metrics import confusion_matrix
import seaborn as sns

def plot_confusion_matrix(y_true, y_pred, classes,
                          normalize=False,
                          title=None,
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if not title:
        if normalize:
            title = 'Normalized confusion matrix'
        else:
            title = 'Confusion matrix, without normalization'

    # Compute confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    # Only use the labels that appear in the data
    classes = classes
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    fig, ax = plt.subplots(figsize=(10,10))    

    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)
    ax.figure.colorbar(im, ax=ax)
    # We want to show all ticks...
    ax.set(xticks=np.arange(cm.shape[1]),
           yticks=np.arange(cm.shape[0]),
           # ... and label them with the respective list entries
           xticklabels=classes, yticklabels=classes,
           title=title,
           ylabel='True label',
           xlabel='Predicted label')

    # Rotate the tick labels and set their alignment.
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right",
             rotation_mode="anchor")

    # Loop over data dimensions and create text annotations.
    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, format(cm[i, j], fmt),
                    ha="center", va="center",
                    color="white" if cm[i, j] > thresh else "black")
    fig.tight_layout()
    return ax

# print(classification_report(list(Y), y_pred))

plot_confusion_matrix(list(Y), y_pred, classes=np.array(["0","1","2","3"]), title='Confusion matrix using KMeans')
```

<img src="å±å¹•å¿«ç…§ 2019-12-15 ä¸‹åˆ4.36.50.png" style="zoom:50%;" />

å¯ä»¥çœ‹åˆ°æ€»ä½“æ¥è¯´ï¼Œå®ˆé—¨å‘˜å‡è¢«åˆ†æˆäº†ä¸€ä¸ªèšç±»ï¼Œå®ˆé—¨å‘˜ç¡®å®æ˜¯è¶³çƒåœºä¸Šçš„â€œç‰¹æ®Šâ€äººæ‰ã€‚

#### 		SPSSç»“æœåˆ†æ

-   é¦–å…ˆæˆ‘ä»¬çš„èšç±»è´¨é‡å¤„äºè‰¯å¥½æ°´å¹³ï¼šä»å³è¾¹çš„é¥¼çŠ¶å›¾ä¸€å¯ä»¥çœ‹åˆ°å„ä¸ªç±»åˆ«çš„å æ¯”åˆ†å¸ƒï¼š

![](å±å¹•å¿«ç…§ 2019-12-15 ä¸‹åˆ7.08.18.png)

-   æˆ‘ä»¬è¿›ä¸€æ­¥æƒ³è¦çŸ¥é“é‚£äº›èƒ½åŠ›å€¼æ˜¯åŒºåˆ†çƒå‘˜ä½ç½®çš„æ ¸å¿ƒï¼š

![](å±å¹•å¿«ç…§ 2019-12-15 ä¸‹åˆ7.09.09.png)ä»ä¸Šé¢å›¾ç‰‡ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒAcceleratoin, Aggression, Agility æ˜¯åŒºåˆ†çƒå‘˜ä½ç½®çš„é‡è¦å› ç´ ã€‚ä¸åŒä½ç½®çƒå‘˜è¿™ä¸‰é¡¹èƒ½åŠ›å€¼åŒºåˆ«è¾ƒå¤§ã€‚

-   é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜å¸Œæœ›çŸ¥é“è¿™æ ·çš„èšç±»å’Œæˆ‘ä»¬çƒå‘˜çš„ä½ç½®ï¼ˆå‰é”‹ï¼Œä¸­åœºï¼Œåå«ï¼Œé—¨å°†ï¼‰é—´çš„å…³è”ï¼š

![](å±å¹•å¿«ç…§ 2019-12-15 ä¸‹åˆ7.13.14.png)

SPSSä¸­ç”¨confuse matrixåˆ†æå¾—åˆ°äº†å’ŒPythonä¸­ä½¿ç”¨sklearn.cluster.KMeansç›¸ä¼¼çš„ç»“æœã€‚

## ï¼ˆå…­ï¼‰åˆ†å·¥è¯´æ˜  

â€‹        æ³¨ï¼šæœ¬å®éªŒä»…æœ‰å®éªŒè€…æœ¬äººç‹¬è‡ªå®Œæˆã€‚

## ï¼ˆä¸ƒï¼‰å‚è€ƒæ–‡çŒ®  

### ä½¿ç”¨åˆ°çš„èµ„æ–™æ±‡æ€»

1.  çº¿æ€§æ¨¡å‹å‚è€ƒæœ¬äººä¹‹å‰åšè¿‡çš„bostonæˆ¿ä»·æ¨¡å‹ï¼š[https://www.kaggle.com/columbine/boston-house-fnn-model](https://www.kaggle.com/columbine/boston-house-fnn-model)
2.  å…³äºæ•°æ®é›†çš„æ„å»ºæ–¹æ³•å‚è€ƒæœ¬äººçš„image caption notebook

[https://www.kaggle.com/columbine/final-project-image-caption](https://www.kaggle.com/columbine/final-project-image-caption)

3.  å…³äºkeraså‚è€ƒkeraså®˜æ–¹æ–‡æ¡£[https://keras.io/zh/](https://keras.io/zh/)
4.  ç®—æ³•æ–¹é¢å…³è”è§„åˆ™åŸç†å‚è€ƒ æ•°æ®ä»“åº“ä¸æ•°æ®æŒ–æ˜è¯¾ç¨‹PPT

### è‡´è°¢

åœ¨è¿™é‡Œå†æ¬¡æ„Ÿè°¢åœ¨æœ¬äººå®Œæˆæœ¬æ¬¡è¯•éªŒè¿‡ç¨‹ä¸­å¸®åŠ©è¿‡æˆ‘çš„è€å¸ˆå’ŒåŒå­¦ã€‚æ„Ÿè°¢æ•°æ®ä»“åº“ä¸æ•°æ®æŒ–æ˜è¯¾ç¨‹æä¾›è¿™æ ·ä¸€æ¬¡ä¸ä»…ä»…å±€é™äºè¯¾æœ¬å†…å®¹ï¼Œå¹¶èƒ½åŠ¨æ‰‹æ“ä½œçš„æœºä¼šã€‚

## ï¼ˆå…«ï¼‰é™„å½•

### 	ï¼ˆä¸€ï¼‰ çƒå‘˜å±æ€§å¯¹åº”å…³ç³»è¡¨

| Attribute          | Explanation                      |
| ------------------ | -------------------------------- |
| finishing          | å®Œæˆå°„é—¨ï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚   |
| heading_accuracy   | å¤´çƒç²¾åº¦ï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚   |
| short_passing      | çŸ­ä¼ ï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚       |
| volleys            | å‡Œç©ºçƒï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚     |
| dribbling          | ç›˜å¸¦ï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚       |
| curve              | å¼§çº¿ï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚       |
| free_kick_accuracy | å®šä½çƒç²¾åº¦ï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚ |
| long_passing       | é•¿ä¼ ï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚       |
| ball_control       | æ§çƒï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚       |

| Attribute    | Explanation                    |
| ------------ | ------------------------------ |
| acceleration | åŠ é€Ÿåº¦ï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚   |
| sprint_speed | å†²åˆºé€Ÿåº¦ï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚ |
| agility      | çµæ´»æ€§ï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚   |
| reactions    | ååº”ï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚     |
| balance      | èº«ä½“åè°ƒï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚ |
| shot_power   | å°„é—¨åŠ›é‡ï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚ |
| jumping      | å¼¹è·³ï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚     |
| stamina      | ä½“èƒ½ï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚     |
| strength     | åŠ›é‡ï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚     |

| Attribute       | Explanation                  |
| --------------- | ---------------------------- |
| long_shots      | è¿œå°„ï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚   |
| aggression      | ä¾µç•¥æ€§ï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚ |
| interceptions   | æ‹¦æˆªï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚   |
| positioning     | ä½ç½®æ„Ÿï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚ |
| vision          | è§†é‡ï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚   |
| penalties       | ç½šç‚¹çƒï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚ |
| marking         | å¡ä½ï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚   |
| standing_tackle | æ–­çƒï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚   |
| sliding_tackle  | é“²çƒï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚   |

| Attribute      | Explanation                      |
| -------------- | -------------------------------- |
| gk_diving      | é—¨å°†æ‰‘æ•‘ï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚   |
| gk_handling    | é—¨å°†æ§çƒï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚   |
| gk_kicking     | é—¨å°†å¼€çƒï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚   |
| gk_positioning | é—¨å°†ä½ç½®æ„Ÿï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚ |
| gk_reflexes    | é—¨å°†ååº”ï¼ˆèƒ½åŠ›å€¼ï¼‰ã€‚æ•°å€¼å˜é‡ã€‚   |

### é™„å½•ï¼ˆäºŒï¼‰æœ¬å®éªŒä¸­ä½¿ç”¨çš„pythonä»£ç 

åœ¨notebookğŸ“ä¸­ï¼Œæ–‡ä»¶æ ¼å¼ä¸º.ipynbæ ¼å¼ï¼Œè€Œä¸æ˜¯.pyæ ¼å¼ï¼Œæ‰“å¼€æ—¶éœ€è¦ä½¿ç”¨jupyter notebookå·¥å…·ã€‚

å½“ç„¶ï¼Œæœ¬å®éªŒçš„notebookå·²ç»åœ¨kaggleä¸Šå…¬å¼€ï¼Œè¿æ¥å¦‚ä¸‹[https://www.kaggle.com/columbine/data-mining-final-project](https://www.kaggle.com/columbine/data-mining-final-project) æ¬¢è¿å¤§å®¶åœ¨kaggleä¸Šviewsï¼Œvotes ï¼